# Springboard's questions
[109 Data Science Interview Questions and Answers | Springboard Blog](https://www.springboard.com/blog/data-science-interview-questions/#)
## Statistics Interview Questions

* What is the Central Limit Theorem and why is it important?
* What is sampling? How many sampling methods do you know?
* What is the difference between type I vs type II error?
* What is linear regression? What do the terms p-value, coefficient, and r-squared value mean? What is the significance of each of these components?
* What are the assumptions required for linear regression?
* What is a statistical interaction?
* What is selection bias?
* What is an example of a data set with a non-Gaussian distribution?
* What is the Binomial Probability Formula?

## Programming
To test your programming skills, employers will typically include two specific data science interview questions: they’ll ask how you would solve programming problems in theory without writing out the code, and then they will also offer whiteboarding exercises for you to code on the spot. For the latter types of questions, we will provide a few examples below, but if you’re looking for in-depth practice solving coding challenges, visit HackerRank. With a "learn by doing" philosophy, there are challenges organized around core concepts commonly tested during interviews.

## General

* With which programming languages and environments are you most comfortable working?
* What are some pros and cons about your favorite statistical software?
* Tell me about an original algorithm you’ve created.
* Describe a data science project in which you worked with a substantial programming component. What did you learn from that experience?
* Do you contribute to any open-source projects?
* How would you clean a data set in (insert language here)?
* Tell me about the coding you did during your last project?

## Big Data

* What are two main components of the Hadoop framework?
* The Hadoop Distributed File System (HDFS), MapReduce, and YARN. Read more here.
* Explain how MapReduce works as simply as possible.
* How would you sort a large list of numbers?
* Say you’re given a large data set. What would be your plan for dealing with outliers? How about missing values? How about transformations?

## Python

* What modules/libraries are you most familiar with? What do you like or dislike about them?
* In Python, how is memory managed?
* In Python, memory is managed in a private heap space. This means that all the objects and data structures will be located in a private heap. However, the programmer won’t be allowed to access this heap. Instead, the Python interpreter will handle it. At the same time, the core API will enable access to some Python tools for the programmer to start coding. The memory manager will allocate the heap space for the Python objects while the inbuilt garbage collector will recycle all the memory that’s not being used to boost available heap space. Read more here.
* What are the supported data types in Python?
* What is the difference between a tuple and a list in Python?

## R

* What are the different types of sorting algorithms available in R language?
* What are the different data objects in R?
* What packages are you most familiar with? What do you like or dislike about them?
* How do you access the element in the 2nd column and 4th row of a matrix named M?
* What is the command used to store R objects in a file?
* What is the best way to use Hadoop and R together for analysis?
* How do you split a continuous variable into different groups/ranks in R?
* Write a function in R language to replace the missing value in a vector with the mean of that vector.

## SQL

Often, SQL questions are case-based, meaning that an employer will task you with solving an SQL problem in order to test your skills from a practical standpoint. For example, you could be given a table and asked to extract relevant data, then filter and order the data as you see fit, and finally report your findings. If you do not feel ready to do this in an interview setting, Mode Analytics has a delightful introduction to using SQL that will teach you these commands through an interactive SQL environment.

* What is the purpose of the group functions in SQL? Give some examples of group functions.
* Group functions are necessary to get summary statistics of a data set. COUNT, MAX, MIN, AVG, SUM, and DISTINCT are all group functions.
* Tell me the difference between an inner join, left join/right join, and union.
* What does UNION do? What is the difference between UNION and UNION ALL?
* What is the difference between SQL and MySQL or SQL Server?
* If a table contains duplicate rows, does a query result display the duplicate values by default? How can you eliminate duplicate rows from a query result?
* For additional SQL questions that focus on looking at specific snippets of code, check out this useful resource created by Toptal.

## Modeling
Data modeling is where a data scientist provides value for a company. Turning data into predictive and actionable information is difficult, talking about it to a potential employer even more so. Practice describing your past experiences building models–what were the techniques used, challenges overcome, and successes achieved in the process? The group of questions below are designed to uncover that information, as well as your formal education of different modeling techniques. If you can’t describe the theory and assumptions associated with a model you’ve used, it won’t leave a good impression.

Take a look at the questions below to practice. Not all of the questions will be relevant to your interview–you’re not expected to be a master of all techniques. The best use of these questions is to re-familiarize yourself with the modeling techniques you’ve learned in the past.

* Tell me about how you designed a model for a past employer or client.
* What are your favorite data visualization techniques?
* How would you effectively represent data with 5 dimensions?
* How is k-NN different from k-means clustering?
* How would you create a logistic regression model?
* Have you used a time series model? Do you understand cross-correlations with time lags?
* Explain the 80/20 rule, and tell me about its importance in model validation.
* Explain what precision and recall are. How do they relate to the ROC curve?
* Explain the difference between L1 and L2 regularization methods.
* What is root cause analysis?
* What are hash table collisions?
* What is an exact test?
* In your opinion, which is more important when designing a machine learning model: model performance or model accuracy?
* What is one way that you would handle an imbalanced data set that’s being used for prediction (i.e., vastly more negative classes than positive classes)?
* How would you validate a model you created to generate a predictive model of a quantitative outcome variable using multiple regression?
* I have two models of comparable accuracy and computational performance. Which one should I choose for production and why?
* How do you deal with sparsity?
* Is it better to spend five days developing a 90-percent accurate solution or 10 days for 100-percent accuracy?
* What are some situations where a general linear model fails?
* Do you think 50 small decision trees are better than a large one? Why?
* When modifying an algorithm, how do you know that your changes are an improvement over not doing anything?
* Is it better to have too many false positives or too many false negatives?

## Past Behavior
Employers love behavioral questions. They reveal information about the work experience of the interviewee and about their demeanor and how that could affect the rest of the team. From these questions, an interviewer wants to see how a candidate has reacted to situations in the past, how well they can articulate what their role was, and what they learned from their experience.

There are several categories of behavioral questions you’ll be asked:

* Teamwork
* Leadership
* Conflict management
* Problem-solving
* Failure
* Before the interview, write down examples of work experiences related to these topics to refresh your memory—you will need to recall specific examples to answer the questions well. When asked about a prior experience, make sure you tell a story. Being able to concisely and logically craft a story to detail your experiences is important. For example: "I was asked X, I did A, B, and C, and decided that the answer was Y."

Of course, if you can highlight experiences having to do with data science, these questions present a great opportunity to showcase a unique accomplishment as a data scientist that you may not have discussed previously.

Here are examples of these sorts of questions/prompts:

* Tell me about a time when you took initiative.
* Tell me about a time when you had to overcome a dilemma.
* Tell me about a time when you resolved a conflict.
* Tell me about a time you failed and what you have learned from it.
* Tell me about (a job on your resume). Why did you choose to do it and what do you like most about it?
* Tell me about a challenge you have overcome while working on a group project.
* When you encountered a tedious, boring task, how would you deal with it and motivate yourself to complete it?
* What have you done in the past to make a client satisfied/happy?
* What have you done in your previous job that you are really proud of?
* What do you do when your personal life is running over into your work life?

## Culture Fit
If an employer asks you a question on this list, they are trying to get a sense of who you are and how you would fit with the company. They’re trying to gauge where your interest in data science and in the hiring company come from. Take a look at these examples and think about what your best answer would be, but keep in mind that it’s important to be honest with these answers. There’s no reason to not be yourself. There are no right answers to these questions, but the best answers are communicated with confidence.

* Which data scientists do you admire most? Which startups?
* What do you think makes a good data scientist?
* How did you become interested in data science?
* Give a few examples of "best practices" in data science.
* What is the latest data science book / article you read? What is the latest data mining conference / webinar / class / workshop / training you attended?
* What’s a project you would want to work on at our company?
* What unique skills do you think you’d bring to the team?
* What data would you love to acquire if there were no limitations?
* Have you ever thought about creating your own startup? Around which idea / concept?
* What can your hobbies tell me that your resume can’t?
* What are your top 5 predictions for the next 20 years?
* What did you do today? Or what did you do this week / last week?
* If you won a million dollars in the lottery, what would you do with the money?
* What is one thing you believe that most people do not?
* What personality traits do you butt heads with?
* What (outside of data science) are you passionate about?

## Problem-Solving
Interviewers will, at some point during the interview process, want to test your problem-solving ability through data science interview questions. Often these tests will be presented as an open-ended question: How would you do X? In general, that X will be a task or problem specific to the company you are applying with. For example, an interviewer at Yelp may ask a candidate how they would create a system to detect fake Yelp reviews.

Some quick tips: Don’t be afraid to ask questions. Employers want to test your critical thinking skills—and asking questions that clarify points of uncertainty is a trait that any data scientist should have. Also, if the problem offers an opportunity to show off your white-board coding skills or to create schematic diagrams—use that to your advantage. It shows technical skill, and helps to communicate your thought process through a different mode of communication. Always share your thought process—process is often more important than the results themselves for the interviewer.

* How would you come up with a solution to identify plagiarism?
* How many "useful" votes will a Yelp review receive?
* How do you detect individual paid accounts shared by multiple users?
* You are about to send a million emails. How do you optimize delivery? How do you optimize response?
* You have a data set containing 100,000 rows and 100 columns, with one of those columns being our dependent variable for a problem we’d like to solve. How can we quickly identify which columns will be helpful in predicting the dependent variable. Identify two techniques and explain them to me as though I were 5 years old.
* How would you detect bogus reviews, or bogus Facebook accounts used for bad purposes?
* How would you perform clustering on a million unique keywords, assuming you have 10 million data points—each one consisting of two keywords, and a metric measuring how similar these two keywords are? How would you create this 10 million data points table in the first place?
* How would you optimize a web crawler to run much faster, extract better information, and better summarize data to produce cleaner databases?

